{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 歌詞分析\n",
    "歌詞分析主要用到的是 <code>jieba.analyse.extract_tags</code>，背後的原理為 tf-idf 算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. tf - idf 簡介 ( term frequency–inverse document frequency )\n",
    "tf - idf 是一種統計方法，此原理為評估一個字詞對於一個檔案集，或一個語料庫中的其中一份檔案的重要程度，這個概念十分重要。\n",
    "\n",
    "<ul>\n",
    "<li> tf (term frequency )：詞頻，計算該詞語在文章所出現的次數</li>\n",
    "<li> idf ( inverse document frequency )：逆文檔頻率，衡量該字詞的重要性</li>\n",
    "</ul>\n",
    "\n",
    "$w_{x,y} = tf_{x,y} \\times \\log{\\left(\\dfrac{N}{df_x}\\right)}$\n",
    "- tf - idf : term x within document y\n",
    "- $tf_{x,y} : \\text{frequency of } x \\text{ in } y.$\n",
    "- $df_{x,y} : \\text{number of documents containing } x.$\n",
    "\n",
    "[Formula of $\\textit{\\textbf{tf - idf}}$](https://miro.medium.com/max/4800/1*n1ReZe2OGaEBYg3kvzYhkQ.png)\n",
    "\n",
    "[Text Clustering : Get quick insights from Unstructured Data](https://miro.medium.com/max/1400/1*4LbwZZRFJZwgqKDyWQl6JA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字詞的重要性隨著它在檔案中**出現的次數成正比增加**，但同時會隨著它在語料庫中**出現的頻率成反比下降**。\n",
    "\n",
    "也就是說，當 tf 值很高，而 df 值很低，這時得到的權重值就能夠把常見的關鍵字濾掉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.analyse\n",
    "jieba.set_dictionary(\"C:\\python310\\lib\\site-packages\\jieba\\dict.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from C:\\python310\\lib\\site-packages\\jieba\\dict.txt ...\n",
      "Loading model from cache C:\\Users\\user\\AppData\\Local\\Temp\\jieba.u18c4b1509d688ff112c4dc9458dfd7be.cache\n",
      "Loading model cost 0.546 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love,14661\n",
      "ing,14661\n",
      "戀愛,7894\n",
      "改變,6766\n",
      "happy,3383\n",
      "噴射機,3383\n",
      "黎明,3026\n",
      "心情,2395\n",
      "心跳,2358\n",
      "沒關,2255\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/single_song.txt\", \"rb\") as f:\n",
    "   for line in f:\n",
    "      tags = jieba.analyse.extract_tags(line, topK=10, withWeight=True)\n",
    "      for tag, weight in tags:\n",
    "         print(tag + \",\" + str(int(weight * 10000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 從歌詞萃取重要關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "時間,一天,會不會,許會,終點,舉起,回憶釀,悠悠的,真的,一杯\n",
      "我們,不曾,哪裡,相識,那個,場景,出現,相遇,每秒,那一刻\n",
      "我們,好好,變老,時間,喧囂,最後的,知道,大人,失散多年,寫成\n",
      "我們,人生,快樂,無論,一個,期待,然後呢,回憶,也許,走著\n",
      "入陣曲,無悔,夜未央,天未亮,倖存,沙場,淚未,心未涼,什麼,此生\n",
      "最好,day,一天,閉上,瞬間,銀河,best,那天,地球,無數\n",
      "OAOA,太短,人生,飢渴,一種,無止,和諧,一個,瞬間,眼淚\n",
      "la,will,high,孤單,怎麼,everything,alright,Tomorrow,fine,High\n",
      "oh,party,hey,let,go,night,lonely,我們,對動物,many\n",
      "什麼,拯救,殘酷,攻擊,能夠,那麼,無策,愛情,結局,束手\n",
      "決定,快樂,保護色,不愛了,靈魂,關在,永遠,鎖上,軀殼,真正\n",
      "一個,兄弟,我們,這樣,怎樣,一點,一次,身旁,人生,一場\n",
      "人生,部門,沒有,過嗎,富貴榮華,目標,飛黃騰,無限,有限,傻瓜\n",
      "盡頭,怎麼樣,終點,有光,我們,成名,那夜,起點,可會亮,綻放\n",
      "變成,交響,我心,每個,孤單,一個,沒人,還有,崩壞,旋律\n",
      "記得,卡片,西天,夥伴,掏耳朵,累不累,荒馬亂,改變過,下滿天,人類\n",
      "怎麼,擁有,快樂,足夠,當一陣,風吹來,風箏,飛上,祈禱,感動\n",
      "我們,人們,未來,無數,如海,怎樣,無數命,運流轉,相異,航向\n",
      "yeah,出現,呼喚,越來,一種,電影,情節,黎明,無法,當我們\n",
      "頑固,一次,深處,活在,淚滴,拼回,一天,吞下,相信,自己\n",
      "do,ever,shine,die,try,現在,jalalan,jalalala,還是,細節\n",
      "人們,改變,容顏,擁有,問你何,以求,春天,就算,終日,難免\n",
      "煩惱,噗通,甩掉,跳越,丟掉,地球,一顆,一瞬,忘掉,再也\n",
      "love,ing,戀愛,改變,happy,噴射機,黎明,心情,心跳,沒關\n",
      "我們,任意,那個,走過,唱片,無數,盡歲,搭著,肩環遊,無法\n",
      "回憶,有人,自傳,終章,愛情,最難,遺忘,原來,飛翔,身旁\n",
      "決定,快樂,傷心,有什麼,潮落,潮起,整個,拋棄,了不起,東西\n",
      "動次,oh,快樂,不管,慢歌,反正,感覺,活著,趴著,音樂\n",
      "一層,空氣,洋蔥,永遠,願意,剝開,你會,沉默,偷偷,如果\n",
      "溫柔,這是,自由,什麼,我給,沒有,不明,想要,單到,那愛情\n",
      "突然,那麼,回憶,好想你,聽到,我們,最怕,空氣,安靜,關心\n",
      "倔強,絕望,一次,握緊,雙手,絕對,驕傲,中大聲,瘋狂,失望\n",
      "總會,一天,不願,甘願,來作,頭腦,米蟲,要安,怎歡,夢中\n",
      "已經,感覺,麥閣,無人,最好,這凍止,免愛我,傷心,這愛你,沒愛我\n",
      "love,無望,這款,法度,逐天,作眠,夢中,可愛的,別人,鐘也\n",
      "轉彎,我要,未來,放棄,規則,放縱,放空,光年,盛夏,放肆\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/mayday.txt\", \"rb\") as f:\n",
    "   for line in f:\n",
    "      tags = jieba.analyse.extract_tags(line, 10)\n",
    "      print(\",\".join(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "時間,會不會,許會,終點,舉起,回憶釀,悠悠的,一杯,真的,一天\n",
      "我們,哪裡,相識,那個,場景,出現,每秒,那一刻,相遇,不曾\n",
      "失散多年,我們,變老,時間,喧囂,寫成,好好,大人,知道\n",
      "我們,快樂,無論,一個,然後呢,回憶,也許,走著,人生,期待\n",
      "夜未央,入陣曲,無悔,天未亮,倖存,沙場,淚未,心未涼,什麼,此生\n",
      "day,閉上,瞬間,銀河,best,無數,那天,地球,最好,一天\n",
      "OAOA,飢渴,一種,無止,和諧,一個,瞬間,眼淚,太短,人生\n",
      "la,will,high,孤單,怎麼,everything,alright,Tomorrow,fine,High\n",
      "oh,party,hey,let,go,night,lonely,我們,對動物,many\n",
      "什麼,殘酷,攻擊,能夠,那麼,無策,愛情,結局,束手,拯救\n",
      "決定,快樂,保護色,不愛了,靈魂,關在,永遠,鎖上,軀殼,真正\n",
      "一個,我們,這樣,怎樣,一點,一場,身旁,人生,兄弟,一次\n",
      "部門,沒有,過嗎,富貴榮華,目標,飛黃騰,無限,傻瓜,人生,有限\n",
      "盡頭,怎麼樣,終點,有光,我們,起點,可會亮,綻放,那夜,成名\n",
      "變成,交響,每個,孤單,一個,沒人,還有,崩壞,我心,旋律\n",
      "夥伴,掏耳朵,累不累,記得,荒馬亂,改變過,下滿天,人類,卡片,西天\n",
      "怎麼,擁有,快樂,足夠,當一陣,風吹來,風箏,飛上,祈禱,感動\n",
      "我們,人們,未來,無數,如海,怎樣,無數命,運流轉,相異,航向\n",
      "yeah,出現,呼喚,越來,一種,電影,情節,無法,當我們,黎明\n",
      "頑固,深處,淚滴,拼回,活在,吞下,相信,一天,一次,自己\n",
      "do,ever,shine,die,try,現在,jalalan,jalalala,還是,細節\n",
      "人們,改變,容顏,擁有,問你何,終日,難免,以求,春天,就算\n",
      "跳越,煩惱,丟掉,一顆,噗通,一瞬,甩掉,忘掉,再也,地球\n",
      "love,ing,戀愛,改變,happy,噴射機,沒關,心跳,黎明,心情\n",
      "我們,那個,走過,無數,盡歲,搭著,肩環遊,無法,唱片,任意\n",
      "回憶,自傳,終章,愛情,最難,遺忘,原來,飛翔,身旁,有人\n",
      "決定,快樂,傷心,有什麼,整個,拋棄,東西,潮落,潮起,了不起\n",
      "動次,oh,快樂,慢歌,感覺,活著,趴著,音樂,反正,不管\n",
      "一層,空氣,洋蔥,永遠,願意,剝開,偷偷,沉默,如果\n",
      "溫柔,這是,什麼,我給,沒有,單到,那愛情,不明,想要,自由\n",
      "那麼,回憶,聽到,我們,空氣,安靜,關心,好想你,突然\n",
      "倔強,絕望,握緊,雙手,絕對,驕傲,中大聲,瘋狂,失望,一次\n",
      "總會,不願,甘願,來作,頭腦,米蟲,要安,怎歡,夢中,一天\n",
      "已經,感覺,麥閣,無人,這凍止,免愛我,傷心,這愛你,沒愛我,最好\n",
      "love,無望,這款,逐天,作眠,夢中,可愛的,別人,鐘也,法度\n",
      "轉彎,我要,未來,放棄,規則,放縱,放空,光年,盛夏,放肆\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "wtags = codecs.open(\"data/mayday_tags.txt\", \"w\", \"utf-8\")\n",
    "with open(\"data/mayday.txt\", \"r\", encoding=\"utf-8\") as f1:\n",
    "   for line in f1:\n",
    "      words = jieba.analyse.extract_tags(line, 10)\n",
    "      wtags.write(\" \".join(words))\n",
    "      wtags.write(\"\\n\")\n",
    "f1.close()\n",
    "\n",
    "with open(\"data/mayday_tags.txt\", \"rb\") as f2:\n",
    "   for line in f2:\n",
    "      tags = jieba.analyse.extract_tags(line,15)\n",
    "      print(\",\".join(tags))\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用 wordcloud 呈現\n",
    "\n",
    "預設是英文字體。\n",
    "\n",
    "※下方code還需要debug，尚不清楚原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('沒有', '一個', '什麼', '那個')\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive - 國立台灣大學\\NTU\\111-1\\DSP\\Markov Chain\\Jieba_Gensim.ipynb Cell 9\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m font \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMSJH.TTC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m wc \u001b[39m=\u001b[39m WordCloud(font_path \u001b[39m=\u001b[39m font,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                background_color \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                max_words \u001b[39m=\u001b[39m \u001b[39m2000\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                stopwords \u001b[39m=\u001b[39m stopwords)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m wc\u001b[39m.\u001b[39;49mgenerate(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/Jieba_Gensim.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m wc\u001b[39m.\u001b[39mto_file(\u001b[39m\"\u001b[39m\u001b[39mdata/output.png\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m     \u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[0;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\wordcloud\\wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m     font_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(\u001b[39mdict\u001b[39;49m(frequencies[:\u001b[39m2\u001b[39;49m]),\n\u001b[0;32m    454\u001b[0m                                    max_font_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight)\n\u001b[0;32m    455\u001b[0m     \u001b[39m# find font sizes\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     sizes \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout_]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\wordcloud\\wordcloud.py:503\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    500\u001b[0m tried_other_orientation \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[39m# try to find a position\u001b[39;00m\n\u001b[1;32m--> 503\u001b[0m     font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39;49mtruetype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfont_path, font_size)\n\u001b[0;32m    504\u001b[0m     \u001b[39m# transpose font optionally\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     transposed_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mTransposedFont(\n\u001b[0;32m    506\u001b[0m         font, orientation\u001b[39m=\u001b[39morientation)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\PIL\\ImageFont.py:844\u001b[0m, in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[0;32m    843\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m     \u001b[39mreturn\u001b[39;00m freetype(font)\n\u001b[0;32m    845\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m    846\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isPath(font):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\PIL\\ImageFont.py:841\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[1;34m(font)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfreetype\u001b[39m(font):\n\u001b[1;32m--> 841\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\PIL\\ImageFont.py:193\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    191\u001b[0m                 load_from_bytes(f)\n\u001b[0;32m    192\u001b[0m             \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mgetfont(\n\u001b[0;32m    194\u001b[0m         font, size, index, encoding, layout_engine\u001b[39m=\u001b[39;49mlayout_engine\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m     load_from_bytes(font)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "from multiprocessing.resource_sharer import stop\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import nltk\n",
    "\n",
    "# 讀取每首歌的前10個tags\n",
    "text = open(\"data/mayday_tags.txt\", 'r', encoding = \"utf-8\").read()\n",
    "text = ' '.join(nltk.word_tokenize(text))\n",
    "# print(text)\n",
    "\n",
    "# 設定停用字(排除常用詞、無法代表特殊意義的字詞)\n",
    "stopwords = (\"沒有\",\"一個\",\"什麼\",\"那個\")\n",
    "\n",
    "# stopwords = set(STOPWORDS)\n",
    "# stopwords.add(\"沒有\")\n",
    "# stopwords.add(\"一個\")\n",
    "# stopwords.add(\"什麼\")\n",
    "# stopwords.add(\"那個\")\n",
    "print(stopwords)\n",
    "\n",
    "# 產生文字雲\n",
    "font = \"MSJH.TTC\"\n",
    "wc = WordCloud(font_path = font,\n",
    "               background_color = \"white\",\n",
    "               max_words = 2000,\n",
    "               stopwords = stopwords)\n",
    "\n",
    "wc.generate(text)\n",
    "wc.to_file(\"data/output.png\")\n",
    "\n",
    "# # 視覺化呈現\n",
    "# plt.imshow(wc)\n",
    "# plt.axis(\"off\")\n",
    "# plt.figure(figsize=(10,6), dpi = 100)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
