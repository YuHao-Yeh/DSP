{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 搜尋字詞：顯現字詞出現的上下文\n",
    "<code>book.concordance()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 38 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "text3.concordance(\"lived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 找近似字\n",
    "<code>book.similar()、book.common_contexts()</code>\n",
    "<p>根據該詞的上下文，找到類似結構，就認定他們為近似字。</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_and\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"monstrous\",\"abundant\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 詞彙多樣性\n",
    "<code>len(set(book))/ len(book)</code>\n",
    "<p>透過計算「相異字詞長度/總字詞長度」的值，去比較不同文本之間涵蓋詞彙的豐富程度。</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10025\n",
      "152901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06556530042314962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text4)\n",
    "sorted(set(text4))\n",
    "\n",
    "print(len(set(text4)), end=\"\\n\")\n",
    "print(len(text4), end=\"\\n\")\n",
    "\n",
    "def lexical_diversity(text):\n",
    "   return len(set(text)) / len(text)\n",
    "lexical_diversity(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 詞彙分布圖\n",
    "<code>book.dispersion_plot()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive - 國立台灣大學\\NTU\\111-1\\DSP\\Markov Chain\\NLTK.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/NLTK.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text4\u001b[39m.\u001b[39;49mdispersion_plot([\u001b[39m\"\u001b[39;49m\u001b[39mcitizens\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdemocracy\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfreedom\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mduties\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAmerica\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mliberty\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mconstitution\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\nltk\\text.py:447\u001b[0m, in \u001b[0;36mText.dispersion_plot\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39mProduce a plot showing the distribution of the words through the text.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39mRequires pylab to be installed.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39m:seealso: nltk.draw.dispersion_plot()\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdraw\u001b[39;00m \u001b[39mimport\u001b[39;00m dispersion_plot\n\u001b[1;32m--> 447\u001b[0m dispersion_plot(\u001b[39mself\u001b[39;49m, words)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\nltk\\draw\\dispersion.py:47\u001b[0m, in \u001b[0;36mdispersion_plot\u001b[1;34m(text, words, ignore_case, title)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     x \u001b[39m=\u001b[39m y \u001b[39m=\u001b[39m ()\n\u001b[1;32m---> 47\u001b[0m pylab\u001b[39m.\u001b[39;49mplot(x, y, \u001b[39m\"\u001b[39;49m\u001b[39mb|\u001b[39;49m\u001b[39m\"\u001b[39;49m, scalex\u001b[39m=\u001b[39;49m\u001b[39m.1\u001b[39;49m)\n\u001b[0;32m     48\u001b[0m pylab\u001b[39m.\u001b[39myticks(\u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(words))), words, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m pylab\u001b[39m.\u001b[39mylim(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(words))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:2769\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2767\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2769\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2770\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2771\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:2274\u001b[0m, in \u001b[0;36mgca\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39mgca)\n\u001b[0;32m   2273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgca\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2274\u001b[0m     \u001b[39mreturn\u001b[39;00m gcf()\u001b[39m.\u001b[39mgca(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:867\u001b[0m, in \u001b[0;36mgcf\u001b[1;34m()\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure\n\u001b[0;32m    866\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m figure()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:798\u001b[0m, in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[0;32m    796\u001b[0m manager \u001b[39m=\u001b[39m _pylab_helpers\u001b[39m.\u001b[39mGcf\u001b[39m.\u001b[39mget_fig_manager(num)\n\u001b[0;32m    797\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 798\u001b[0m     max_open_warning \u001b[39m=\u001b[39m rcParams[\u001b[39m'\u001b[39;49m\u001b[39mfigure.max_open_warning\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(allnums) \u001b[39m==\u001b[39m max_open_warning \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    800\u001b[0m         _api\u001b[39m.\u001b[39mwarn_external(\n\u001b[0;32m    801\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMore than \u001b[39m\u001b[39m{\u001b[39;00mmax_open_warning\u001b[39m}\u001b[39;00m\u001b[39m figures have been opened. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFigures created through the pyplot interface \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarning, see the rcParam `figure.max_open_warning`).\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    806\u001b[0m             \u001b[39mRuntimeWarning\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\", \"liberty\", \"constitution\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 文本的結合\n",
    "<code>sent1 + sent2</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Call', 'me', 'Ishmael', '.']\n",
      "['The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in', 'Sussex', '.']\n",
      "['Call', 'me', 'Ishmael', '.', 'The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in', 'Sussex', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sent1, end=\"\\n\")\n",
    "\n",
    "print(sent2, end=\"\\n\")\n",
    "\n",
    "print(sent1 + sent2, end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK 中文文本\n",
    "\n",
    "使用 jieba 執行中文斷詞與特徵萃取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 搜尋字詞\n",
    "\n",
    "透過 <code>jieba.analyse.extract_tags</code> 取出中文文本當中的關鍵字，背後是使用 tf — idf 的概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 不曾 哪裡 相識 那個 場景 出現 相遇 每秒 那一刻 我會 充滿 如果 \n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 好好 變老 時間 喧囂 最後的 知道 大人 失散多年 寫成 想養 每個 場\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 人生 快樂 無論 一個 期待 然後呢 回憶 也許 走著 並肩 追尋了 親愛\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 依然 魑魅 一份 解愁 城牆\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 對動物 many 瘋狂 goodbye 覺悟 good times 日出 \n",
      "No matches\n",
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 這樣 怎樣 一點 一次 身旁 人生 一場 變成 別來 無恙 抬頭 永遠 時\n",
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 成名 那夜 起點 可會亮 綻放 回頭望 一雙 風光 那路 怎樣 少年 一站\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 戰場 一線 無論 一樣 至少 天亮 心中\n",
      "No matches\n",
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 人們 未來 無數 如海 怎樣 無數命 運流轉 相異 航向 汪洋 小孩 打造\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 任意 那個 走過 唱片 無數 盡歲 搭著 肩環遊 無法 遺忘 光輝 門外 \n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "Displaying 1 of 1 matches:\n",
      "                                      我們 最怕 空氣 安靜 關心 翻滾 絞痛 悲傷 哪裡 過得 快樂 鋒利 平息 委\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n",
      "No matches\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "import nltk\n",
    "with open(\"data/mayday.txt\", encoding=\"utf-8\") as f1:\n",
    "   for line in f1:\n",
    "      lyrics= nltk.text.Text(jieba.analyse.extract_tags(line))\n",
    "      lyrics.concordance(\"我們\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 近似字\n",
    "\n",
    "<code>jieba.cut()</code> 用來做中文斷詞\n",
    "\n",
    "<code>nltk.text.Text()</code> 讓文本成為 NLTK 可以吃的格式。\n",
    "\n",
    "<code>nltk.similar(\"我們\")</code>，找到「我們」的近似字\n",
    "\n",
    "* 包含「我」、「青春」、「身邊」…等\n",
    "* 「我」跟「我們」會出現在 『讓_不 』這樣的結構當中，因此他們被判定為近似字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 青春 身邊 完美 難題 倔強 地方 街 路 陷阱 空氣 眼中 憤青 剝開 破壞\n",
      "讓_不\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "raw = open(\"data/mayday.txt\", encoding=\"utf-8\").read()\n",
    "lyrics = nltk.text.Text(jieba.cut(raw))\n",
    "lyrics.similar(\"我們\")\n",
    "lyrics.common_contexts([\"我們\", \"我\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 詞彙多樣性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3114754098360656"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = open(\"data/single_song.txt\", encoding=\"utf-8\").read()\n",
    "single = nltk.text.Text(jieba.cut(raw))\n",
    "lexical_diversity(single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 詞彙分布圖\n",
    "\n",
    "<code>single.dispersion_plot()</code>呈現關鍵歌詞之間的先後順序，以及頻率分佈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\OneDrive - 國立台灣大學\\NTU\\111-1\\DSP\\Markov Chain\\NLTK.ipynb Cell 22\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/NLTK.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/NLTK.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# plt.figure(figsize=(10, 5))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/NLTK.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# plt.rcParams['font.sans-serif'] = 'SimHei'\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/OneDrive%20-%20%E5%9C%8B%E7%AB%8B%E5%8F%B0%E7%81%A3%E5%A4%A7%E5%AD%B8/NTU/111-1/DSP/Markov%20Chain/NLTK.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m single\u001b[39m.\u001b[39;49mdispersion_plot([\u001b[39m\"\u001b[39;49m\u001b[39mlove\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39m戀愛\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39ming\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mhappy\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\nltk\\text.py:447\u001b[0m, in \u001b[0;36mText.dispersion_plot\u001b[1;34m(self, words)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39mProduce a plot showing the distribution of the words through the text.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39mRequires pylab to be installed.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[39m:seealso: nltk.draw.dispersion_plot()\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdraw\u001b[39;00m \u001b[39mimport\u001b[39;00m dispersion_plot\n\u001b[1;32m--> 447\u001b[0m dispersion_plot(\u001b[39mself\u001b[39;49m, words)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\nltk\\draw\\dispersion.py:47\u001b[0m, in \u001b[0;36mdispersion_plot\u001b[1;34m(text, words, ignore_case, title)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     x \u001b[39m=\u001b[39m y \u001b[39m=\u001b[39m ()\n\u001b[1;32m---> 47\u001b[0m pylab\u001b[39m.\u001b[39;49mplot(x, y, \u001b[39m\"\u001b[39;49m\u001b[39mb|\u001b[39;49m\u001b[39m\"\u001b[39;49m, scalex\u001b[39m=\u001b[39;49m\u001b[39m.1\u001b[39;49m)\n\u001b[0;32m     48\u001b[0m pylab\u001b[39m.\u001b[39myticks(\u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(words))), words, color\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m pylab\u001b[39m.\u001b[39mylim(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(words))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:2769\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2767\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2769\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2770\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2771\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:2274\u001b[0m, in \u001b[0;36mgca\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[39m.\u001b[39mgca)\n\u001b[0;32m   2273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgca\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2274\u001b[0m     \u001b[39mreturn\u001b[39;00m gcf()\u001b[39m.\u001b[39mgca(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:867\u001b[0m, in \u001b[0;36mgcf\u001b[1;34m()\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[39mreturn\u001b[39;00m manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure\n\u001b[0;32m    866\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m figure()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\pyplot.py:798\u001b[0m, in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[0;32m    796\u001b[0m manager \u001b[39m=\u001b[39m _pylab_helpers\u001b[39m.\u001b[39mGcf\u001b[39m.\u001b[39mget_fig_manager(num)\n\u001b[0;32m    797\u001b[0m \u001b[39mif\u001b[39;00m manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 798\u001b[0m     max_open_warning \u001b[39m=\u001b[39m rcParams[\u001b[39m'\u001b[39;49m\u001b[39mfigure.max_open_warning\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(allnums) \u001b[39m==\u001b[39m max_open_warning \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    800\u001b[0m         _api\u001b[39m.\u001b[39mwarn_external(\n\u001b[0;32m    801\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMore than \u001b[39m\u001b[39m{\u001b[39;00mmax_open_warning\u001b[39m}\u001b[39;00m\u001b[39m figures have been opened. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFigures created through the pyplot interface \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarning, see the rcParam `figure.max_open_warning`).\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    806\u001b[0m             \u001b[39mRuntimeWarning\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "\n",
    "single.dispersion_plot([\"love\",\"戀愛\",\"ing\",\"happy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
